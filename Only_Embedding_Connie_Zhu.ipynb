{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHmarYG9kGac",
        "outputId": "e4d87a3e-18fd-4edd-99d1-11a251df849a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beOsktd3kH4-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "import spacy\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MB-6Xyg_kPDV",
        "outputId": "3778dfb5-e6e6-4775-b72e-98b7a71fec7c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-03a1c3fa-4f6f-468e-8eaf-f8b757f2b320\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "      <td>quebec nationalist see province nation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "      <td>adopted dog would encourage people adopt shop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "      <td>velocity affect time velocity affect space geo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "      <td>otto von guericke used magdeburg hemisphere</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "      <td>convert montra helicon mountain bike changing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03a1c3fa-4f6f-468e-8eaf-f8b757f2b320')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-03a1c3fa-4f6f-468e-8eaf-f8b757f2b320 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-03a1c3fa-4f6f-468e-8eaf-f8b757f2b320');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0                                      question_text  target  \\\n",
              "0           0  How did Quebec nationalists see their province...       0   \n",
              "1           1  Do you have an adopted dog, how would you enco...       0   \n",
              "2           2  Why does velocity affect time? Does velocity a...       0   \n",
              "3           3  How did Otto von Guericke used the Magdeburg h...       0   \n",
              "4           4  Can I convert montra helicon D to a mountain b...       0   \n",
              "\n",
              "                                          clean_text  \n",
              "0            quebec nationalist see province nation   \n",
              "1     adopted dog would encourage people adopt shop   \n",
              "2  velocity affect time velocity affect space geo...  \n",
              "3       otto von guericke used magdeburg hemisphere   \n",
              "4  convert montra helicon mountain bike changing ...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_clean = pd.read_csv('./train_clean.csv')\n",
        "train_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1EvOwUEkS8t",
        "outputId": "0158757e-dd23-4f92-d0a5-dcb33ef4bad6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1917495it [01:56, 16476.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1917495 word vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# embdedding setup\n",
        "# Source https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html\n",
        "embeddings_index = {}\n",
        "EMBEDDING_FILE = './glove.42B.300d.txt' # define embedding file path\n",
        "\n",
        "with open(EMBEDDING_FILE, 'r', encoding=\"utf-8\") as f:\n",
        "  for line in tqdm(f):\n",
        "      values = line.split(\" \")\n",
        "      word = values[0]\n",
        "      coefs = np.asarray(values[1:], dtype='float32')\n",
        "      embeddings_index[word] = coefs\n",
        "  f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "furUZpoflVS0",
        "outputId": "58c3643f-9a0c-4bb6-f9fb-617a7b3caefb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:00<00:00, 18872.32it/s]\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df = train_test_split(train_clean.drop('clean_text',axis=1), test_size=0.07)\n",
        "def text_to_array(text):\n",
        "    empyt_emb = np.zeros(300)\n",
        "    text = text[:-1].split()[:30]\n",
        "    embeds = [embeddings_index.get(x, empyt_emb) for x in text]\n",
        "    embeds+= [empyt_emb] * (30 - len(embeds))\n",
        "    return np.array(embeds)\n",
        "\n",
        "# train_vects = [text_to_array(X_text) for X_text in tqdm(train_df[\"question_text\"])]\n",
        "val_vects = np.array([text_to_array(X_text) for X_text in tqdm(val_df[\"question_text\"][:3000])])\n",
        "val_y = np.array(val_df[\"target\"][:3000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Mb5YisoDma"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99Gyx1n-lZjU"
      },
      "outputs": [],
      "source": [
        "# Data providers\n",
        "batch_size = 128\n",
        "\n",
        "def batch_gen(train_df):\n",
        "    n_batches = math.ceil(len(train_df) / batch_size)\n",
        "    while True: \n",
        "        train_df = train_df.sample(frac=1.)  # Shuffle the data.\n",
        "        for i in range(n_batches):\n",
        "            texts = train_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
        "            text_arr = np.array([text_to_array(text) for text in texts])\n",
        "            yield text_arr, np.array(train_df[\"target\"][i*batch_size:(i+1)*batch_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0kjzp-vmlNj",
        "outputId": "1a360681-1ec8-4e9d-88cf-c727c263cb81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 30, 128)          187392    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 30, 128)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              99328     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 286,849\n",
            "Trainable params: 286,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True), input_shape=(30, 300)))\n",
        "model.add(SpatialDropout1D(0.1))\n",
        "model.add(Bidirectional(CuDNNLSTM(64)))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0tX6tx3mnXM",
        "outputId": "b4a402b3-83f3-45d5-c575-8ea6c9ad75ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1000/1000 [==============================] - 26s 15ms/step - loss: 0.1511 - accuracy: 0.9442 - val_loss: 0.1473 - val_accuracy: 0.9430\n",
            "Epoch 2/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1358 - accuracy: 0.9478 - val_loss: 0.1444 - val_accuracy: 0.9430\n",
            "Epoch 3/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1321 - accuracy: 0.9491 - val_loss: 0.1417 - val_accuracy: 0.9417\n",
            "Epoch 4/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1289 - accuracy: 0.9505 - val_loss: 0.1452 - val_accuracy: 0.9463\n",
            "Epoch 5/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1265 - accuracy: 0.9510 - val_loss: 0.1330 - val_accuracy: 0.9497\n",
            "Epoch 6/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1263 - accuracy: 0.9504 - val_loss: 0.1331 - val_accuracy: 0.9457\n",
            "Epoch 7/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1247 - accuracy: 0.9513 - val_loss: 0.1349 - val_accuracy: 0.9453\n",
            "Epoch 8/30\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1237 - accuracy: 0.9520 - val_loss: 0.1301 - val_accuracy: 0.9483\n",
            "Epoch 9/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1237 - accuracy: 0.9519 - val_loss: 0.1307 - val_accuracy: 0.9503\n",
            "Epoch 10/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1190 - accuracy: 0.9537 - val_loss: 0.1290 - val_accuracy: 0.9510\n",
            "Epoch 11/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1187 - accuracy: 0.9533 - val_loss: 0.1277 - val_accuracy: 0.9533\n",
            "Epoch 12/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1169 - accuracy: 0.9546 - val_loss: 0.1325 - val_accuracy: 0.9523\n",
            "Epoch 13/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1150 - accuracy: 0.9547 - val_loss: 0.1295 - val_accuracy: 0.9517\n",
            "Epoch 14/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1173 - accuracy: 0.9538 - val_loss: 0.1262 - val_accuracy: 0.9540\n",
            "Epoch 15/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1165 - accuracy: 0.9542 - val_loss: 0.1307 - val_accuracy: 0.9493\n",
            "Epoch 16/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1162 - accuracy: 0.9545 - val_loss: 0.1275 - val_accuracy: 0.9490\n",
            "Epoch 17/30\n",
            "1000/1000 [==============================] - 13s 13ms/step - loss: 0.1143 - accuracy: 0.9550 - val_loss: 0.1277 - val_accuracy: 0.9490\n",
            "Epoch 18/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1140 - accuracy: 0.9551 - val_loss: 0.1228 - val_accuracy: 0.9513\n",
            "Epoch 19/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1136 - accuracy: 0.9555 - val_loss: 0.1310 - val_accuracy: 0.9477\n",
            "Epoch 20/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1096 - accuracy: 0.9571 - val_loss: 0.1258 - val_accuracy: 0.9507\n",
            "Epoch 21/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1088 - accuracy: 0.9570 - val_loss: 0.1278 - val_accuracy: 0.9497\n",
            "Epoch 22/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1078 - accuracy: 0.9572 - val_loss: 0.1261 - val_accuracy: 0.9513\n",
            "Epoch 23/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1104 - accuracy: 0.9557 - val_loss: 0.1248 - val_accuracy: 0.9483\n",
            "Epoch 24/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1084 - accuracy: 0.9572 - val_loss: 0.1262 - val_accuracy: 0.9527\n",
            "Epoch 25/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1089 - accuracy: 0.9563 - val_loss: 0.1251 - val_accuracy: 0.9513\n",
            "Epoch 26/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1108 - accuracy: 0.9561 - val_loss: 0.1242 - val_accuracy: 0.9507\n",
            "Epoch 27/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1102 - accuracy: 0.9564 - val_loss: 0.1256 - val_accuracy: 0.9517\n",
            "Epoch 28/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1079 - accuracy: 0.9578 - val_loss: 0.1248 - val_accuracy: 0.9487\n",
            "Epoch 29/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1043 - accuracy: 0.9584 - val_loss: 0.1241 - val_accuracy: 0.9500\n",
            "Epoch 30/30\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.1003 - accuracy: 0.9600 - val_loss: 0.1247 - val_accuracy: 0.9517\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2dcc1b24d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mg = batch_gen(train_df)\n",
        "model.fit(mg, epochs=30,\n",
        "                    steps_per_epoch=1000,\n",
        "                    validation_data=(val_vects, val_y),\n",
        "                    verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0olCSy7Sa_o"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import load_model\n",
        "model.save('./LSTM.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjRVYvsWTA3F"
      },
      "outputs": [],
      "source": [
        "model = load_model('./LSTM.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3fpuoi4XA1I"
      },
      "outputs": [],
      "source": [
        "test_text = np.array([text_to_array(\"Which babies are more sweeter to their parents? Dark skin babies or light skin babies?\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD6Ypx64XNId",
        "outputId": "9197e34c-0744-4f40-8872-ad13f76bb8c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [-0.33160999,  0.040621  , -0.43906   , ...,  0.3249    ,\n",
              "          0.1026    ,  0.18494   ],\n",
              "        [-0.32144001,  0.11529   ,  0.009374  , ..., -0.28773001,\n",
              "          0.22002999,  0.19564   ],\n",
              "        ...,\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ]]])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WlqgvXhYX2W",
        "outputId": "00fdbcef-7f88-4630-a0b6-c2549e686dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 438ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-72-e05452cfa1ce>:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_te = (np.array(all_predict) > 0.5).astype(np.int)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0.5705933], dtype=float32)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_predict = model.predict(test_text).flatten()\n",
        "y_te = (np.array(all_predict) > 0.5).astype(np.int)\n",
        "y_te\n",
        "all_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueR6-KO9YeSi",
        "outputId": "d6e59c44-7a0a-47ca-def0-c7b790136ff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_te"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
